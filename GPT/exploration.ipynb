{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3146c6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " = Valkyria Chronicles III = \n",
      " \n",
      " Senjō no Valkyria 3 : Unrecorded Chronicles ( Japanese : 戦場のヴァルキュリア3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game in the Valkyria series . Employing the same fusion of tactical and real @-@ time gameplay as its predecessors , the story runs parallel to the first game and follows the \" Nameless \" , a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" Calamaty Raven \" . \n",
      " The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II . While it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more forgiving for series \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "with open('data/wikitext-2-raw/wiki.train.raw', 'r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "with open('data/wikitext-2-raw/wiki.valid.raw', 'r') as f:\n",
    "    valid = f.read()\n",
    "\n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f76269d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10918892"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250d9640",
   "metadata": {},
   "source": [
    "getting vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e99a132e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'w', 'á', 'ჶ', '蘇', 'მ', 'ả', '漢', '²', 'ş', 'ý', 'エ', 'ː', 'í', 'ܕ', 'ร', 'f', 'е', 'ჹ', 'à', 'ù', 'タ', 'ാ', 'đ', 'а', 'さ', 'ذ', 'Ν', 'モ', '昌', '酈', 'ل', 'ჱ', 'Đ', '天', '寝', 'ი', 'क', 'Р', 'ỹ', '^', '憶', 'ح', '①', 'أ', '립', 'о', 'セ', 'А', 'å', '`', 'य', 'ź', 'ع', 'ʕ', '其', '府', 'პ', 'e', '部', 'け', 'Ⴌ', 'a', 'г', 'ფ', '½', 'ห', 'デ', 'M', 'ศ', 'ג', 'Ā', '…', 'š', 'Ö', 'æ', 'ộ', 'ღ', 'ィ', 'ม', 'Χ', '彩', '丙', 'な', '韓', 'আ', 'н', '球', 'Ō', '珂', 'ჭ', '\\n', '拳', 'χ', '揺', 'ไ', 'ー', 'ي', 'ȯ', '陽', '少', 'С', 'ქ', 'ზ', 'İ', 'ญ', 'S', '♭', 'ォ', '楚', '跡', 'A', 'μ', '清', 'ɫ', '〉', '世', 'ơ', '遠', '拉', 'с', '้', '华', 'Ĕ', 'ū', 'ø', 'Ḥ', 'ゲ', '真', 'ấ', 'ỳ', 'ß', '林', '挑', 'λ', '旭', '規', '⚳', '費', '國', 'ɡ', '七', 'द', 'ァ', '.', '2', '“', '建', 'ů', '礮', '병', 'ז', 'ọ', '辛', '坂', 'ʁ', '蘄', '澤', '沙', 'º', 'л', 'ų', '珙', 'ē', 'ส', '梶', '്', 'Y', 'も', 'ब', '’', '人', 'ゆ', '二', '铁', 'ك', '灵', 'B', '鍵', '約', 'ɐ', 'ﷲ', '#', 'β', '夫', 'ს', 'ś', 'π', 'と', 'Ⴀ', 'ā', '大', 'ق', 'J', '山', '扈', '〈', 'キ', '都', 'ま', '€', 'ğ', 'แ', 'T', 'サ', '雲', '中', '〜', '師', 'Ó', 'ี', '精', 'ะ', 'Ç', 'ţ', 'x', 'ク', '대', '織', '庆', '[', 'ɪ', '্', 'ף', '阿', 'В', 'ਲ', '州', 'の', '³', 'ậ', '再', '‑', 'ึ', '技', 'ń', 'に', 'ư', 'ベ', 'ּ', '裁', '誓', '束', 'و', 'フ', 'こ', '九', '可', '兵', 'Č', 'в', 'テ', 'ミ', 'ę', 'だ', '化', 'ב', 'न', '應', 'ნ', '−', 'γ', 'ܝ', '郭', '熱', 'ἀ', 'ʋ', 'Ⴕ', 'ê', '§', '″', '／', '選', '式', 'ỗ', '正', 'ば', 'ɒ', 'ჴ', '芽', '巳', 'Г', 'ḥ', 'ょ', 'Κ', 'ツ', 'c', '転', 'അ', '汉', '機', 'ว', 'カ', '́', 'U', '生', 'ノ', 'レ', 'č', 'ḷ', 'ρ', '高', '5', '椎', 'კ', '⅓', '藥', 'ˈ', '懷', 'ñ', '誰', '北', '₣', 'ള', 'す', '灯', 'ぎ', 'й', '!', '足', 'ჰ', 'ắ', 'ค', 'µ', '同', '/', 'ɑ', '부', 'ョ', '遇', 'ʒ', '~', '榮', 'ิ', 'ἰ', '狸', '興', 'H', 'が', 'う', 'ж', 'ü', 'か', \"'\", ')', 'ʔ', '母', 'ˌ', '‡', '野', 'া', 'ḏ', '\\u200b', 'ż', 'ł', 'm', 'Ω', 'ฮ', '～', 'ず', '充', '₹', 'े', 'ネ', '>', '李', '砲', 'ν', '命', '\"', 'ứ', 'ã', 'Ś', '德', '„', 'έ', '棘', '耕', '岳', 'र', ' ', '₤', 'ჩ', 'ご', '제', '小', 'म', '運', ',', '霖', '殿', 'ễ', 'ت', '今', 'უ', 'þ', 'ס', '夕', 'У', '‐', '霹', 'к', '1', 'ه', '曦', 'Б', 'ʾ', 'خ', '未', '=', 'ჵ', 'ह', '7', 'リ', 'ה', '´', 'W', '隊', '–', 'ת', 'き', '良', '政', '¿', '白', 'ि', 'ั', 'み', 'b', '神', '明', 'Я', '豪', 'ъ', 'ラ', '჻', 'ι', 'ό', 'ξ', 'ჟ', 'ר', 'é', 'ء', '波', 'ე', 'Î', 'R', 'い', 'อ', '臂', 'ʃ', '理', 'ੱ', '祈', '玩', 'ै', '橘', '廬', 'É', 'L', '里', '本', 'D', 'ς', '湯', 'ป', 'â', '咲', '′', 'ï', '・', 'k', 'ム', '̯', 'ج', 'ੁ', '立', '宗', '+', 'ח', '보', 'ヘ', '≤', 'τ', 'お', 'თ', '•', 'ਾ', 'ή', 'め', '厂', 'ώ', 'Ž', '堤', '依', '&', '$', '泗', 'ภ', '子', 'は', '广', 'ش', 'd', 'ė', 'ô', 'ო', 'у', 'ჺ', '物', 'ά', 'Ä', '安', '翠', '番', '杜', '史', '晋', '瓊', 'я', 'ă', ';', '塘', 'ạ', '―', '之', 'θ', '琪', 'Ⴟ', 'ხ', '日', 'ჷ', 'Φ', '洪', '願', '光', 'ɽ', 'ﻋ', 'ズ', 'ы', 'N', '桜', '戦', 'く', 'プ', 'ც', 'ử', 'Z', '龍', 'ッ', 'ჲ', '火', '後', 'ĕ', 'ち', 'ω', 'ܢ', '旦', '¡', '琦', 'ָ', 'Ⴃ', '信', 'ί', 'I', '芳', '乙', '傳', '張', 'ɔ', '\\x94', '望', '๊', '°', '陈', 'ر', '防', 'ジ', '絵', 'შ', 'ტ', '‘', 'C', '守', 'ֹ', 'Ł', '¢', 'ا', 'م', 'د', 'ὁ', '\\\\', 'ฐ', 'ỏ', '彌', '玄', '月', '→', '憑', 'ة', 'り', 'ܲ', '斯', 'V', '许', '集', 'К', '沂', 'ܬ', 'し', 'ܗ', 'G', 'F', 'α', 'ვ', 'Ē', '覺', 'ũ', 'イ', 'წ', 'ύ', 'あ', 'Ú', 'ܠ', '金', '去', '0', 'व', '畢', 'ナ', 'ʿ', '♯', 'œ', 'ị', 'ο', '君', '階', '楊', 'ა', 'ž', '胡', 'ث', 'ഹ', '錄', 'ř', 'ダ', 'დ', 'გ', '孟', 'ハ', 'р', '春', 'ス', 'п', 'Α', '%', 'h', 'ʼ', '円', '่', 'พ', '思', 'O', 'シ', 'Í', 'ħ', '四', 'ṃ', '場', '̃', 'Š', 'Ü', 'ن', 'ʲ', 'प', '鋼', '儚', 'Ż', 'ف', 'и', '座', 'П', '愛', '解', '淹', '殻', 'ɢ', '×', 'ṣ', 'グ', 'ュ', '赤', '�', '一', 'ु', '瘡', '藕', ':', '過', 'अ', '알', 'ן', '放', '谭', 'Δ', 'ì', 'ə', '豫', 'ბ', '战', '出', '和', '8', 'Ⴂ', 'ǎ', '澄', 'ṇ', '⁄', '名', '誡', 'つ', '贵', 'Á', 'ふ', 'ド', 'ɛ', '下', '吳', 'ṯ', 'た', 'を', 'p', 'o', 'י', 'ं', 'א', '記', 'ð', 'є', 'j', '妙', 'オ', '侗', 'হ', '@', 't', 'ซ', '靂', 'ル', 'ō', '主', 'ग', 'l', 'q', 'נ', 'ロ', '劉', '皮', 'ɾ', 'ん', '平', 'X', 'ा', 'ャ', '銃', 'ぜ', 'ὀ', 'ყ', '台', 'ほ', 'ガ', '9', '̥', 'Å', 'Ñ', '-', 'る', 'P', 's', 'ε', 'т', 'っ', 'ニ', 'ṛ', 'Π', 'η', '古', 'บ', '寺', 'ц', 'Æ', 'Ø', '關', 'צ', '秋', 'स', 'ʊ', 'ლ', '6', '邱', 'ệ', 'ֵ', 'ầ', 'ш', 'ț', 'ゃ', '方', 'Ľ', '♀', '<', '연', 'ớ', '☫', 'チ', '泣', 'z', '３', '钱', '(', 'ص', 'υ', 'ン', 'ई', '姚', 'ण', '散', 'i', '行', '}', '謎', 'ı', '¥', '†', '͍', 'E', 'ณ', 'ᵻ', '̍', '付', '逆', '陳', '4', '鐵', 'ต', '景', 'ä', 'ī', 'إ', 'Τ', 'ू', '宋', 'ง', '顯', 'ჳ', 'ด', '女', 'ト', 'ò', 'ܐ', 'ย', 'น', 'ö', 'ჯ', 'ก', 'ア', 'Ş', 'ਅ', 'v', 'რ', 'ب', '善', '乃', '|', '圣', 'ल', '劇', 'ヴ', 'Þ', '宫', '्', 'わ', 'れ', '독', 'Q', 'ɳ', '⅔', '☉', '英', 'ল', '์', 'ș', 'ψ', 'y', 'ֶ', '狐', '若', '肖', '云', 'Ⴈ', 'ล', '水', '邦', 'K', 'า', '完', 'ṭ', 'è', 'ჸ', 'マ', 'ą', 'ェ', '宝', 'ǔ', '颜', 'з', 'n', '彼', 'ษ', '祠', 'ɜ', '空', '前', '焼', '作', '±', '村', 'ל', 'ם', '—', '3', '田', 'ゥ', 'パ', 'σ', 'û', 'מ', 'ʻ', 'ë', '河', '剛', 'เ', 'ὑ', 'ь', '_', '判', 'ら', 'ç', '·', 'Х', '動', '£', 'त', 'ữ', 'ひ', '膀', '观', 'コ', 'κ', '≡', '具', '市', '義', 'х', '川', '者', 'ю', 'ぐ', 'ძ', 'ć', 'ש', '周', 'ú', '御', '趙', 'ṅ', 'ó', 'ช', 'ブ', 'ܵ', '马', '”', '\\ufeff', 'д', '全', '在', 'פ', 'δ', '攻', 'м', '灼', '雪', 'î', '尾', '花', '?', 'Ș', '来', ']', '王', '園', 'ḍ', '錡', '\\x93', 'ਹ', 'u', 'r', '็', '*', 'س', 'バ', 'ו', '라', '星', 'g'}\n",
      "\n",
      " !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz|}~¡¢£¥§°±²³´µ·º½¿ÁÄÅÆÇÉÍÎÑÓÖ×ØÚÜÞßàáâãäåæçèéêëìíîïðñòóôöøùúûüýþĀāăąćČčĐđĒēĔĕėęğħīİıĽŁłńŌōœřŚśŞşŠšţũūůųźŻżŽžơưǎǔȘșțȯɐɑɒɔəɛɜɡɢɪɫɳɽɾʁʃʊʋʒʔʕʲʻʼʾʿˈˌː̥̯͍́̃̍ΑΔΚΝΠΤΦΧΩάέήίαβγδεηθικλμνξοπρςστυχψωόύώАБВГКПРСУХЯавгдежзийклмнопрстухцшъыьюяєֵֶָֹּאבגהוזחילםמןנסףפצרשתءأإابةتثجحخدذرسشصعفقكلمنهويܐܕܗܝܠܢܬܲܵंअईकगणतदनपबमयरलवसहािुूेै्আলহা্ਅਲਹਾੁੱഅളഹാ്กคงชซญฐณดตนบปพภมยรลวศษสหอฮะัาิีึเแไ็่้๊์ႠႢႣႨႬႵႿაბგდევზთიკლმნოპჟრსტუფქღყშჩცძწჭხჯჰჱჲჳჴჵჶჷჸჹჺ჻ᵻḍḏḤḥḷṃṅṇṛṣṭṯạảấầậắễệịọỏỗộớứửữỳỹἀἰὀὁὑ​‐‑–—―‘’“”„†‡•…′″⁄₣₤€₹⅓⅔→−≡≤①☉☫♀♭♯⚳〈〉〜あいうおかがきぎくぐけこごさしすずぜただちっつとなにのはばひふほまみめもゃゆょらりるれわをんァアィイゥェエォオカガキクグゲコサシジスズセタダチッツテデトドナニネノハバパフブプヘベマミムモャュョラリルレロンヴ・ー一七下世丙中主乃之乙九二云人今付作侗依信傳儚充光全兵其具円再出判前剛劇劉動化北华厂去古可台史同名君吳周命和咲善四國園圣在坂堤場塘夕大天夫女妙姚子孟守安宋完宗宝宫寝寺小少尾山岳川州巳市師平广庆府座廬建式張彌彩彼後御德思愛憑憶應懷战戦扈技拉拳挑揺攻放政散斯方日旦旭昌明星春晋景曦月望未本李村杜束来林桜梶棘椎楊楚榮橘機正殻殿母水汉沂沙河泗波泣洪淹清湯漢澄澤火灯灵灼焼熱物狐狸玄王玩珂珙球理琦琪瓊生田畢番瘡白皮真砲礮祈神祠秋空立精約絵織義翠者耕肖胡膀臂興良花芳芽若英藕藥蘄蘇行裁規覺观解記誓誡誰謎许谭豪豫費贵赤趙足跡転辛逆遇運過遠選邦邱部郭都酈里野金銃鋼錄錡鍵鐵钱铁關防阿陈陳陽隊階集雪雲霖霹靂韓願顯颜马高龍대독라립병보부알연제ﷲﻋ﻿／３～�\n",
      "1013\n"
     ]
    }
   ],
   "source": [
    "print(set(text)) # set of all characters\n",
    "chars = sorted(list(set(text))) #sorted and in a list\n",
    "vocab_size = len(chars) # number of unique characters\n",
    "print(''.join(chars)) # print all characters\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7382575c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['w', 'á', 'ჶ', '蘇', 'მ', 'ả', '漢', '²', 'ş', 'ý', 'エ', 'ː', 'í', 'ܕ', 'ร', 'f', 'е', 'ჹ', 'à', 'ù', 'タ', 'ാ', 'đ', 'а', 'さ', 'ذ', 'Ν', 'モ', '昌', '酈', 'ل', 'ჱ', 'Đ', '天', '寝', 'ი', 'क', 'Р', 'ỹ', '^', '憶', 'ح', '①', 'أ', '립', 'о', 'セ', 'А', 'å', '`', 'य', 'ź', 'ع', 'ʕ', '其', '府', 'პ', 'e', '部', 'け', 'Ⴌ', 'a', 'г', 'ფ', '½', 'ห', 'デ', 'M', 'ศ', 'ג', 'Ā', '…', 'š', 'Ö', 'æ', 'ộ', 'ღ', 'ィ', 'ม', 'Χ', '彩', '丙', 'な', '韓', 'আ', 'н', '球', 'Ō', '珂', 'ჭ', '\\n', '拳', 'χ', '揺', 'ไ', 'ー', 'ي', 'ȯ', '陽', '少', 'С', 'ქ', 'ზ', 'İ', 'ญ', 'S', '♭', 'ォ', '楚', '跡', 'A', 'μ', '清', 'ɫ', '〉', '世', 'ơ', '遠', '拉', 'с', '้', '华', 'Ĕ', 'ū', 'ø', 'Ḥ', 'ゲ', '真', 'ấ', 'ỳ', 'ß', '林', '挑', 'λ', '旭', '規', '⚳', '費', '國', 'ɡ', '七', 'द', 'ァ', '.', '2', '“', '建', 'ů', '礮', '병', 'ז', 'ọ', '辛', '坂', 'ʁ', '蘄', '澤', '沙', 'º', 'л', 'ų', '珙', 'ē', 'ส', '梶', '്', 'Y', 'も', 'ब', '’', '人', 'ゆ', '二', '铁', 'ك', '灵', 'B', '鍵', '約', 'ɐ', 'ﷲ', '#', 'β', '夫', 'ს', 'ś', 'π', 'と', 'Ⴀ', 'ā', '大', 'ق', 'J', '山', '扈', '〈', 'キ', '都', 'ま', '€', 'ğ', 'แ', 'T', 'サ', '雲', '中', '〜', '師', 'Ó', 'ี', '精', 'ะ', 'Ç', 'ţ', 'x', 'ク', '대', '織', '庆', '[', 'ɪ', '্', 'ף', '阿', 'В', 'ਲ', '州', 'の', '³', 'ậ', '再', '‑', 'ึ', '技', 'ń', 'に', 'ư', 'ベ', 'ּ', '裁', '誓', '束', 'و', 'フ', 'こ', '九', '可', '兵', 'Č', 'в', 'テ', 'ミ', 'ę', 'だ', '化', 'ב', 'न', '應', 'ნ', '−', 'γ', 'ܝ', '郭', '熱', 'ἀ', 'ʋ', 'Ⴕ', 'ê', '§', '″', '／', '選', '式', 'ỗ', '正', 'ば', 'ɒ', 'ჴ', '芽', '巳', 'Г', 'ḥ', 'ょ', 'Κ', 'ツ', 'c', '転', 'അ', '汉', '機', 'ว', 'カ', '́', 'U', '生', 'ノ', 'レ', 'č', 'ḷ', 'ρ', '高', '5', '椎', 'კ', '⅓', '藥', 'ˈ', '懷', 'ñ', '誰', '北', '₣', 'ള', 'す', '灯', 'ぎ', 'й', '!', '足', 'ჰ', 'ắ', 'ค', 'µ', '同', '/', 'ɑ', '부', 'ョ', '遇', 'ʒ', '~', '榮', 'ิ', 'ἰ', '狸', '興', 'H', 'が', 'う', 'ж', 'ü', 'か', \"'\", ')', 'ʔ', '母', 'ˌ', '‡', '野', 'া', 'ḏ', '\\u200b', 'ż', 'ł', 'm', 'Ω', 'ฮ', '～', 'ず', '充', '₹', 'े', 'ネ', '>', '李', '砲', 'ν', '命', '\"', 'ứ', 'ã', 'Ś', '德', '„', 'έ', '棘', '耕', '岳', 'र', ' ', '₤', 'ჩ', 'ご', '제', '小', 'म', '運', ',', '霖', '殿', 'ễ', 'ت', '今', 'უ', 'þ', 'ס', '夕', 'У', '‐', '霹', 'к', '1', 'ه', '曦', 'Б', 'ʾ', 'خ', '未', '=', 'ჵ', 'ह', '7', 'リ', 'ה', '´', 'W', '隊', '–', 'ת', 'き', '良', '政', '¿', '白', 'ि', 'ั', 'み', 'b', '神', '明', 'Я', '豪', 'ъ', 'ラ', '჻', 'ι', 'ό', 'ξ', 'ჟ', 'ר', 'é', 'ء', '波', 'ე', 'Î', 'R', 'い', 'อ', '臂', 'ʃ', '理', 'ੱ', '祈', '玩', 'ै', '橘', '廬', 'É', 'L', '里', '本', 'D', 'ς', '湯', 'ป', 'â', '咲', '′', 'ï', '・', 'k', 'ム', '̯', 'ج', 'ੁ', '立', '宗', '+', 'ח', '보', 'ヘ', '≤', 'τ', 'お', 'თ', '•', 'ਾ', 'ή', 'め', '厂', 'ώ', 'Ž', '堤', '依', '&', '$', '泗', 'ภ', '子', 'は', '广', 'ش', 'd', 'ė', 'ô', 'ო', 'у', 'ჺ', '物', 'ά', 'Ä', '安', '翠', '番', '杜', '史', '晋', '瓊', 'я', 'ă', ';', '塘', 'ạ', '―', '之', 'θ', '琪', 'Ⴟ', 'ხ', '日', 'ჷ', 'Φ', '洪', '願', '光', 'ɽ', 'ﻋ', 'ズ', 'ы', 'N', '桜', '戦', 'く', 'プ', 'ც', 'ử', 'Z', '龍', 'ッ', 'ჲ', '火', '後', 'ĕ', 'ち', 'ω', 'ܢ', '旦', '¡', '琦', 'ָ', 'Ⴃ', '信', 'ί', 'I', '芳', '乙', '傳', '張', 'ɔ', '\\x94', '望', '๊', '°', '陈', 'ر', '防', 'ジ', '絵', 'შ', 'ტ', '‘', 'C', '守', 'ֹ', 'Ł', '¢', 'ا', 'م', 'د', 'ὁ', '\\\\', 'ฐ', 'ỏ', '彌', '玄', '月', '→', '憑', 'ة', 'り', 'ܲ', '斯', 'V', '许', '集', 'К', '沂', 'ܬ', 'し', 'ܗ', 'G', 'F', 'α', 'ვ', 'Ē', '覺', 'ũ', 'イ', 'წ', 'ύ', 'あ', 'Ú', 'ܠ', '金', '去', '0', 'व', '畢', 'ナ', 'ʿ', '♯', 'œ', 'ị', 'ο', '君', '階', '楊', 'ა', 'ž', '胡', 'ث', 'ഹ', '錄', 'ř', 'ダ', 'დ', 'გ', '孟', 'ハ', 'р', '春', 'ス', 'п', 'Α', '%', 'h', 'ʼ', '円', '่', 'พ', '思', 'O', 'シ', 'Í', 'ħ', '四', 'ṃ', '場', '̃', 'Š', 'Ü', 'ن', 'ʲ', 'प', '鋼', '儚', 'Ż', 'ف', 'и', '座', 'П', '愛', '解', '淹', '殻', 'ɢ', '×', 'ṣ', 'グ', 'ュ', '赤', '�', '一', 'ु', '瘡', '藕', ':', '過', 'अ', '알', 'ן', '放', '谭', 'Δ', 'ì', 'ə', '豫', 'ბ', '战', '出', '和', '8', 'Ⴂ', 'ǎ', '澄', 'ṇ', '⁄', '名', '誡', 'つ', '贵', 'Á', 'ふ', 'ド', 'ɛ', '下', '吳', 'ṯ', 'た', 'を', 'p', 'o', 'י', 'ं', 'א', '記', 'ð', 'є', 'j', '妙', 'オ', '侗', 'হ', '@', 't', 'ซ', '靂', 'ル', 'ō', '主', 'ग', 'l', 'q', 'נ', 'ロ', '劉', '皮', 'ɾ', 'ん', '平', 'X', 'ा', 'ャ', '銃', 'ぜ', 'ὀ', 'ყ', '台', 'ほ', 'ガ', '9', '̥', 'Å', 'Ñ', '-', 'る', 'P', 's', 'ε', 'т', 'っ', 'ニ', 'ṛ', 'Π', 'η', '古', 'บ', '寺', 'ц', 'Æ', 'Ø', '關', 'צ', '秋', 'स', 'ʊ', 'ლ', '6', '邱', 'ệ', 'ֵ', 'ầ', 'ш', 'ț', 'ゃ', '方', 'Ľ', '♀', '<', '연', 'ớ', '☫', 'チ', '泣', 'z', '３', '钱', '(', 'ص', 'υ', 'ン', 'ई', '姚', 'ण', '散', 'i', '行', '}', '謎', 'ı', '¥', '†', '͍', 'E', 'ณ', 'ᵻ', '̍', '付', '逆', '陳', '4', '鐵', 'ต', '景', 'ä', 'ī', 'إ', 'Τ', 'ू', '宋', 'ง', '顯', 'ჳ', 'ด', '女', 'ト', 'ò', 'ܐ', 'ย', 'น', 'ö', 'ჯ', 'ก', 'ア', 'Ş', 'ਅ', 'v', 'რ', 'ب', '善', '乃', '|', '圣', 'ल', '劇', 'ヴ', 'Þ', '宫', '्', 'わ', 'れ', '독', 'Q', 'ɳ', '⅔', '☉', '英', 'ল', '์', 'ș', 'ψ', 'y', 'ֶ', '狐', '若', '肖', '云', 'Ⴈ', 'ล', '水', '邦', 'K', 'า', '完', 'ṭ', 'è', 'ჸ', 'マ', 'ą', 'ェ', '宝', 'ǔ', '颜', 'з', 'n', '彼', 'ษ', '祠', 'ɜ', '空', '前', '焼', '作', '±', '村', 'ל', 'ם', '—', '3', '田', 'ゥ', 'パ', 'σ', 'û', 'מ', 'ʻ', 'ë', '河', '剛', 'เ', 'ὑ', 'ь', '_', '判', 'ら', 'ç', '·', 'Х', '動', '£', 'त', 'ữ', 'ひ', '膀', '观', 'コ', 'κ', '≡', '具', '市', '義', 'х', '川', '者', 'ю', 'ぐ', 'ძ', 'ć', 'ש', '周', 'ú', '御', '趙', 'ṅ', 'ó', 'ช', 'ブ', 'ܵ', '马', '”', '\\ufeff', 'д', '全', '在', 'פ', 'δ', '攻', 'м', '灼', '雪', 'î', '尾', '花', '?', 'Ș', '来', ']', '王', '園', 'ḍ', '錡', '\\x93', 'ਹ', 'u', 'r', '็', '*', 'س', 'バ', 'ו', '라', '星', 'g']\n"
     ]
    }
   ],
   "source": [
    "print(list(set(text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39e7813",
   "metadata": {},
   "source": [
    "# tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49d69e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[73, 70, 77, 77, 80, 1, 88, 80, 83, 77, 69]\n",
      "hello world\n"
     ]
    }
   ],
   "source": [
    "#@title 'Very Simple char level tokeniser'\n",
    "s_to_i={ch: i for i, ch in enumerate(chars)} # map from character to index string to interger\n",
    "i_to_s={i: ch for i, ch in enumerate(chars)} # map from index to character\n",
    "\n",
    "encode = lambda s: [s_to_i[c] for c in s] # function to encode a string to a list of integers\n",
    "decode = lambda l: ''.join([i_to_s[i] for i in l]) # function to decode a list of integers to a string\n",
    "print(encode('hello world'))\n",
    "print(decode(encode('hello world')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d9358f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31373, 995]\n",
      "[11274, 16390, 995]\n",
      "hello world\n"
     ]
    }
   ],
   "source": [
    "# using tiktoken\n",
    "import tiktoken\n",
    "encoding = tiktoken.get_encoding(\"gpt2\")\n",
    "print(encoding.encode(\"hello world\"))\n",
    "\n",
    "print(encoding.encode(\"goodbye world\"))\n",
    "print(encoding.decode(encoding.encode(\"hello world\")))\n",
    "vocab_size = encoding.n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3508c3d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gpt2', 'r50k_base', 'p50k_base', 'p50k_edit', 'cl100k_base', 'o200k_base']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiktoken.list_encoding_names() # list of all available encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abdec7a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f955cff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e57537b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  220,   198,   796,   569, 18354,  7496, 17740,  6711,   796,   220,\n",
       "          198,   220,   198,  2311,    73, 13090,   645,   569, 18354,  7496,\n",
       "          513,  1058,   791, 47398, 17740,   357,  4960,  1058, 10545,   230,\n",
       "           99,   161,   254,   112,  5641, 44444,  9202, 25084, 24440, 12675,\n",
       "        11839,    18,   837,  6578,   764,   569, 18354,  7496,   286,   262,\n",
       "        30193,   513,  1267,   837,  8811,  6412,   284,   355,   569, 18354,\n",
       "         7496, 17740,  6711,  2354,  2869,   837,   318,   257, 16106,  2597,\n",
       "         2488,    12,    31,  2712,  2008,   983,  4166,   416, 29490,   290,\n",
       "         6343,    13, 44206,   329,   262, 14047, 44685,   764, 28728,   287,\n",
       "         3269,  2813,   287,  2869,   837,   340,   318,   262,  2368,   983],\n",
       "       device='mps:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data = torch.tensor(encoding.encode(text), dtype=torch.long, device=device) # convert the text to a tensor of integers\n",
    "test = torch.tensor(encoding.encode(valid), dtype=torch.long, device=device) # convert the validation text to a tensor of integers\n",
    "data[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b492a61",
   "metadata": {},
   "source": [
    "Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6ea237b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: tensor([220], device='mps:0'), target: 198\n",
      "context: tensor([220, 198], device='mps:0'), target: 796\n",
      "context: tensor([220, 198, 796], device='mps:0'), target: 569\n",
      "context: tensor([220, 198, 796, 569], device='mps:0'), target: 18354\n",
      "context: tensor([  220,   198,   796,   569, 18354], device='mps:0'), target: 7496\n",
      "context: tensor([  220,   198,   796,   569, 18354,  7496], device='mps:0'), target: 17740\n",
      "context: tensor([  220,   198,   796,   569, 18354,  7496, 17740], device='mps:0'), target: 6711\n",
      "context: tensor([  220,   198,   796,   569, 18354,  7496, 17740,  6711],\n",
      "       device='mps:0'), target: 796\n"
     ]
    }
   ],
   "source": [
    "block_size = 8\n",
    "\n",
    "x = data[:block_size] # first 256 characters\n",
    "y = data[1:block_size+1] # next 256 characters\n",
    "\n",
    "for i in range(block_size):\n",
    "    context = x[:i+1] # context is the first character\n",
    "    target = y[i] # target is the next character\n",
    "    print(f'context: {context}, target: {target}') # print the context and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51b28f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3173,  4001,   339,   373,  5906,   284,  1210,  4708],\n",
      "        [33738,   706,  1918,   837,   290,   416,   262,   968],\n",
      "        [16842, 20230,   764,   383, 11301,   287,   262, 32022],\n",
      "        [ 4762,   284,   588,   851, 40108,   837,   450,   333]],\n",
      "       device='mps:0')\n",
      "tensor([[ 4001,   339,   373,  5906,   284,  1210,  4708,   379],\n",
      "        [  706,  1918,   837,   290,   416,   262,   968,  7526],\n",
      "        [20230,   764,   383, 11301,   287,   262, 32022,  2066],\n",
      "        [  284,   588,   851, 40108,   837,   450,   333,   363]],\n",
      "       device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4 # 4 parallel sequences\n",
    "block_size = 8 # 8 characters in each sequence\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    batch_data = data if split == 'train' else test\n",
    "    ix = torch.randint(len(batch_data) - block_size, (batch_size,)) # random starting index for each sequence\n",
    "    x = torch.stack([batch_data[i:i+block_size] for i in ix]) # stack the sequences into a batch makes it a 2d tensor in this case matrix which is batchsize x block_size\n",
    "    # x is a batch of sequences, each sequence is block_size characters long\n",
    "    # y is the same as x but shifted one character to the right\n",
    "    # so that the target is the next character in the sequence\n",
    "    y = torch.stack([batch_data[i+1:i+block_size+1] for i in ix]) # stack the targets into a batch\n",
    "    return x, y # return the inputs and targets\n",
    "\n",
    "x,y = get_batch('train') # get a batch of data\n",
    "print(x)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f643816c",
   "metadata": {},
   "source": [
    "# Baseline model Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79b11e66",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Invalid buffer size: 9.41 GB",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m logits\n\u001b[1;32m     14\u001b[0m model \u001b[38;5;241m=\u001b[39m BiGram(vocab_size)\n\u001b[0;32m---> 15\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m output \u001b[38;5;241m=\u001b[39m model(x, y) \u001b[38;5;66;03m# get the output of the model\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(output\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;66;03m# should be batch_size x block_size x vocab_size\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1340\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1337\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1338\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:927\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 927\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    930\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1326\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1320\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1321\u001b[0m             device,\n\u001b[1;32m   1322\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1323\u001b[0m             non_blocking,\n\u001b[1;32m   1324\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1325\u001b[0m         )\n\u001b[0;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Invalid buffer size: 9.41 GB"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BiGram(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets):\n",
    "        logits = self.token_embedding_table(idx) # get the logits for the input indices\n",
    "        # logits is a batch_size x block_size x vocab_size tensor\n",
    "        return logits\n",
    "\n",
    "model = BiGram(vocab_size)\n",
    "model.to(device)\n",
    "output = model(x, y) # get the output of the model\n",
    "print(output.shape) # should be batch_size x block_size x vocab_size\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
