{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6483e5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS is available\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[0.4413, 0.9246, 0.8919],\n",
      "        [0.3129, 0.4724, 0.1688],\n",
      "        [0.0034, 0.3959, 0.3472]])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]], device='mps:0')\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor(5)\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]]])\n",
      "tensor([[[[0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    print(\"MPS is available\")\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    print(\"CUDA is available\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "#empty tensor\n",
    "tensor = torch.empty(3, 3)  # Create a 3x3 empty tensor\n",
    "print(tensor)\n",
    "#random tensor\n",
    "tensor = torch.rand(3, 3)  # Create a 3x3 tensor with random values\n",
    "print(tensor)\n",
    "#tensor with specific values\n",
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])  # Create a tensor with specific values\n",
    "print(tensor)\n",
    "#tensor with specific data type\n",
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float32)  # Create a tensor with specific data type\n",
    "print(tensor)\n",
    "#tensor with specific device\n",
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6]], device=device)  # Create a tensor on GPU\n",
    "print(tensor)\n",
    "#tensor with specific shape\n",
    "tensor = torch.zeros((2, 3))  # Create a tensor filled with zeros\n",
    "print(tensor)\n",
    "# scalar tensor\n",
    "tensor = torch.tensor(5)  # Create a scalar tensor\n",
    "print(tensor)\n",
    "# empty tensor\n",
    "tensor = torch.empty(2, 3)  # Create a 2x3 empty tensor\n",
    "print(tensor)\n",
    "# 3d tensor\n",
    "tensor = torch.empty(2, 3, 4)  # Create a 2x3x4 empty tensor\n",
    "print(tensor)\n",
    "# 4d tensor\n",
    "tensor = torch.empty(2, 3, 4, 5)  # Create a 2x3x4x5 empty tensor\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f98b66a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "#tensor from list\n",
    "tensor = torch.tensor([[1, 2], [3, 4]])  # Create a tensor from a list\n",
    "print(tensor)\n",
    "#tensor from numpy array\n",
    "numpy_array = np.array([[1, 2], [3, 4]])  # Create a numpy array\n",
    "tensor = torch.tensor(numpy_array)  # Create a tensor from a numpy array\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5785141a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6,  8],\n",
      "        [10, 12]])\n",
      "tensor([[-4, -4],\n",
      "        [-4, -4]])\n",
      "tensor([[ 5, 12],\n",
      "        [21, 32]])\n",
      "tensor([[0.2000, 0.3333],\n",
      "        [0.4286, 0.5000]])\n",
      "tensor([[19, 22],\n",
      "        [43, 50]])\n",
      "tensor([[19, 22],\n",
      "        [43, 50]])\n"
     ]
    }
   ],
   "source": [
    "#addition\n",
    "x = torch.tensor([[1, 2], [3, 4]])\n",
    "y = torch.tensor([[5, 6], [7, 8]])\n",
    "z = x + y  # Element-wise addition\n",
    "print(z)\n",
    "#subtraction\n",
    "a = x-y  # Element-wise subtraction\n",
    "print(a)\n",
    "#element-wise multiplication\n",
    "b = x * y  # Element-wise multiplication\n",
    "print(b)\n",
    "#element-wise division\n",
    "c = x / y  # Element-wise division\n",
    "print(c)\n",
    "#matrix multiplication\n",
    "d = torch.matmul(x, y)  # Matrix multiplication\n",
    "print(d)\n",
    "#alternatively use the @ operator\n",
    "e = x @ y  # Matrix multiplication using @ operator (inbuilt)\n",
    "print(e)\n",
    "\n",
    "#torch.add, torch.sub, torch.mul, torch.div all with *_ variants\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084201bd",
   "metadata": {},
   "source": [
    "if function has a trailing underscore is equivalent to an inplace in pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c56e499b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0960, 0.2850, 0.7176],\n",
      "        [0.5223, 0.7585, 0.0523],\n",
      "        [0.3432, 0.5486, 0.3696],\n",
      "        [0.1472, 0.2933, 0.3405],\n",
      "        [0.0453, 0.4501, 0.3001]])\n",
      "first row: tensor([0.0960, 0.2850, 0.7176])\n",
      "second column: tensor([0.2850, 0.7585, 0.5486, 0.2933, 0.4501])\n",
      "slicing a sub-tensor: tensor([[0.5223, 0.7585],\n",
      "        [0.3432, 0.5486]])\n"
     ]
    }
   ],
   "source": [
    "#slicing\n",
    "x = torch.rand(5,3)\n",
    "print(x)\n",
    "print('first row:', x[0])  # First row\n",
    "print('second column:', x[:, 1])  # Second column\n",
    "print('slicing a sub-tensor:', x[1:3, 0:2])  # Slicing a sub-tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8b4aa0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6385, 0.6482, 0.2863],\n",
      "        [0.0037, 0.1160, 0.1877],\n",
      "        [0.0181, 0.4074, 0.7145],\n",
      "        [0.5746, 0.1157, 0.6554],\n",
      "        [0.0583, 0.4863, 0.5466]])\n",
      "max value: 0.7144843935966492\n",
      "min value: 0.0036944150924682617\n",
      "mean value: 0.36380448937416077\n",
      "sum value: 5.457067489624023\n",
      "argmax: 8\n",
      "argmin: 3\n"
     ]
    }
   ],
   "source": [
    "#extracting values with item\n",
    "x = torch.rand(5, 3)\n",
    "print(x)\n",
    "print('max value:', x.max().item())  # Maximum value\n",
    "print('min value:', x.min().item())  # Minimum value\n",
    "print('mean value:', x.mean().item())  # Mean value\n",
    "print('sum value:', x.sum().item())  # Sum of all elements\n",
    "#argmax, argmin\n",
    "print('argmax:', x.argmax().item())  # Index of maximum value\n",
    "print('argmin:', x.argmin().item())  # Index of minimum value\n",
    "#nb item only works for 0D tensors ie scalar tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fde6975e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1242, 0.5110, 0.1652, 0.2965],\n",
      "        [0.8697, 0.5020, 0.1726, 0.3385],\n",
      "        [0.2633, 0.1402, 0.7215, 0.3171],\n",
      "        [0.6423, 0.3071, 0.2401, 0.3371]])\n",
      "original shape: torch.Size([4, 4])\n",
      "alternative shape: torch.Size([4, 4])\n",
      "----------\n",
      "tensor([[0.1242, 0.5110, 0.1652, 0.2965, 0.8697, 0.5020, 0.1726, 0.3385],\n",
      "        [0.2633, 0.1402, 0.7215, 0.3171, 0.6423, 0.3071, 0.2401, 0.3371]])\n",
      "----------\n",
      "tensor([[0.1242, 0.5110, 0.1652, 0.2965, 0.8697, 0.5020, 0.1726, 0.3385],\n",
      "        [0.2633, 0.1402, 0.7215, 0.3171, 0.6423, 0.3071, 0.2401, 0.3371]])\n",
      "----------\n",
      "tensor([0.1242, 0.5110, 0.1652, 0.2965, 0.8697, 0.5020, 0.1726, 0.3385, 0.2633,\n",
      "        0.1402, 0.7215, 0.3171, 0.6423, 0.3071, 0.2401, 0.3371]) with shape: torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "#reshaping\n",
    "x = torch.rand(4, 4)\n",
    "print(x)\n",
    "print('original shape:', x.shape)\n",
    "print('alternative shape:', x.size())\n",
    "print('-'*10)\n",
    "y = x.view(2, 8)  # Reshape to 2x8\n",
    "print(y)\n",
    "print('-'*10)\n",
    "z = x.view(-1, 8)  # Reshape to 2x8 (automatic dimension calculation)\n",
    "print(z)\n",
    "print('-'*10)\n",
    "#flatten\n",
    "a = x.flatten()  # Flatten the tensor\n",
    "print(a,'with shape:', a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c52f7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor x: tensor([[0.7122, 0.4159, 0.3849],\n",
      "        [0.4031, 0.9929, 0.5394],\n",
      "        [0.5996, 0.1222, 0.7743]]) <class 'torch.Tensor'>\n",
      "numpy_array: [[0.7122124  0.4159354  0.38485473]\n",
      " [0.40308082 0.9929341  0.53942573]\n",
      " [0.599593   0.12224352 0.7742742 ]] <class 'numpy.ndarray'>\n",
      "tensor x: tensor([[1.7122, 1.4159, 1.3849],\n",
      "        [1.4031, 1.9929, 1.5394],\n",
      "        [1.5996, 1.1222, 1.7743]]) <class 'torch.Tensor'>\n",
      "numpy_array: [[1.7122123 1.4159354 1.3848548]\n",
      " [1.4030808 1.9929341 1.5394257]\n",
      " [1.5995929 1.1222435 1.7742741]] <class 'numpy.ndarray'>\n",
      "numpy_array y: [[1 2]\n",
      " [3 4]] <class 'numpy.ndarray'>\n",
      "tensor_y: tensor([[1, 2],\n",
      "        [3, 4]]) <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "#to numpy\n",
    "x = torch.rand(3, 3)\n",
    "print(f'tensor x: {x}', type(x))\n",
    "numpy_array = x.numpy()  # Convert to numpy array\n",
    "print(f'numpy_array: {numpy_array}', type(numpy_array))\n",
    "# NB it uses the same memory as the tensor, so modifying one will modify the other\n",
    "x.add_(1)  # Add 1 to the tensor\n",
    "print(f'tensor x: {x}', type(x))\n",
    "print(f'numpy_array: {numpy_array}', type(numpy_array))\n",
    "\n",
    "y = np.array([[1, 2], [3, 4]])  # Create a numpy array\n",
    "print(f'numpy_array y: {y}', type(y))\n",
    "tensor_y = torch.from_numpy(y, dtype=torch.float64)  # Convert to tensor\n",
    "print(f'tensor_y: {tensor_y}', type(tensor_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "80e9ba6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]], requires_grad=True)\n",
      "tensor([[3., 4.],\n",
      "        [5., 6.]], grad_fn=<AddBackward0>)\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "#requires grad\n",
    "x = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32, requires_grad=True)  # Create a tensor with gradient tracking\n",
    "print(x)\n",
    "y = x + 2  # Perform an operation\n",
    "print(y)\n",
    "y.backward(torch.ones_like(y))  # Backpropagation\n",
    "print(x.grad)  # Gradient of x\n",
    "# NB requires_grad=True is only needed for the input tensor, not the output tensor\n",
    "# NB backward() only works for scalar tensors, so we need to pass a gradient of the same shape as y\n",
    "# NB backward() accumulates gradients, so we need to zero the gradients before each backward pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
